{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "import gym\n",
    "import random\n",
    "import time\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA = .62\n",
    "ALPHA = .7\n",
    "BATCH_SIZE = 128\n",
    "MIN_REPLAY_SIZE = 1000\n",
    "SAMPLE_SIZE = 50000\n",
    "MAX_EPOCHS = 1000\n",
    "EPS_DECAY = .001\n",
    "EPSILON_INITIAL = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, state_size, action_size):\n",
    "        super(Net, self).__init__()\n",
    "        learning_rate = 0.001\n",
    "        self.w1 = nn.Linear(state_size, 24)\n",
    "        self.w2 = nn.Linear(24, 12)\n",
    "        self.w3 = nn.Linear(12, action_size)\n",
    "        self.loss_ = nn.SmoothL1Loss()\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.w1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.w2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.w3(x)\n",
    "        return x\n",
    "    \n",
    "    def backwards(self, my_loss):\n",
    "        self.optimizer.zero_grad()\n",
    "        my_loss.backward()\n",
    "        self.optimizer.step()\n",
    "    \n",
    "    def loss(self, y_ex, y_act):\n",
    "        return self.loss_(y_ex, y_act)\n",
    "\n",
    "def train(replay_memory, main, target, batch_size):\n",
    "    if len(replay_memory) < MIN_REPLAY_SIZE:\n",
    "        return # wait till replay memory filled\n",
    "    \n",
    "    mini_batch = random.sample(replay_memory, batch_size)\n",
    "    s_tminus1 = [memory[0] for memory in mini_batch]\n",
    "    s_tminus1 = torch.FloatTensor(s_tminus1)\n",
    "    qs_tminus1 = main.forward(s_tminus1)\n",
    "    \n",
    "    s_t = [memory[3] for memory in mini_batch]\n",
    "    s_t = torch.FloatTensor(s_t)\n",
    "    qs_t = target.forward(s_t)\n",
    "    \n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    # Gather Ys Q values for model\n",
    "    for index, (prev_obs, reward, action, obs, done) in enumerate(mini_batch):\n",
    "        q_tminus1 = qs_tminus1[index]\n",
    "        q_max = torch.max(qs_t[index])\n",
    "        if (not done):\n",
    "            sample = reward + GAMMA * q_max\n",
    "        else:\n",
    "            sample = reward\n",
    "\n",
    "        q_tminus1[action] = (1-ALPHA) * q_tminus1[action] + ALPHA * sample \n",
    "        X.append(prev_obs)\n",
    "        Y.append(q_tminus1.tolist())\n",
    "\n",
    "    # run minibatch\n",
    "#     print(Y)\n",
    "    Y_act = main.forward(torch.FloatTensor(X))\n",
    "    loss = main.loss(torch.FloatTensor(Y), Y_act)\n",
    "    if (batch_size > BATCH_SIZE):\n",
    "        print(loss)\n",
    "    main.backwards(loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (w1): Linear(in_features=4, out_features=24, bias=True)\n",
      "  (w2): Linear(in_features=24, out_features=12, bias=True)\n",
      "  (w3): Linear(in_features=12, out_features=2, bias=True)\n",
      "  (loss_): SmoothL1Loss()\n",
      ")\n",
      "Net(\n",
      "  (w1): Linear(in_features=4, out_features=24, bias=True)\n",
      "  (w2): Linear(in_features=24, out_features=12, bias=True)\n",
      "  (w3): Linear(in_features=12, out_features=2, bias=True)\n",
      "  (loss_): SmoothL1Loss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "main = Net(4,2)\n",
    "target = copy.deepcopy(main)\n",
    "print(target)\n",
    "print(main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 finished\n",
      "Epoch 1 finished\n",
      "Epoch 2 finished\n",
      "Epoch 3 finished\n",
      "Epoch 4 finished\n",
      "Epoch 5 finished\n",
      "Epoch 6 finished\n",
      "Epoch 7 finished\n",
      "Epoch 8 finished\n",
      "Epoch 9 finished\n",
      "tensor(0.1057, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 10 finished\n",
      "tensor(0.0820, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 11 finished\n",
      "tensor(0.0744, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 12 finished\n",
      "tensor(0.0714, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 13 finished\n",
      "tensor(0.0732, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 14 finished\n",
      "tensor(0.0693, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 15 finished\n",
      "tensor(0.0570, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 16 finished\n",
      "tensor(0.0414, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 17 finished\n",
      "tensor(0.0281, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 18 finished\n",
      "tensor(0.0207, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 19 finished\n",
      "tensor(0.0164, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 20 finished\n",
      "tensor(0.0151, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 21 finished\n",
      "tensor(0.0135, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 22 finished\n",
      "tensor(0.0130, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 23 finished\n",
      "tensor(0.0127, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 24 finished\n",
      "tensor(0.0124, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 25 finished\n",
      "tensor(0.0121, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 26 finished\n",
      "tensor(0.0113, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 27 finished\n",
      "tensor(0.0111, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 28 finished\n",
      "tensor(0.0108, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 29 finished\n",
      "tensor(0.0104, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 30 finished\n",
      "tensor(0.0102, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 31 finished\n",
      "tensor(0.0100, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 32 finished\n",
      "tensor(0.0098, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 33 finished\n",
      "tensor(0.0096, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 34 finished\n",
      "tensor(0.0094, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 35 finished\n",
      "tensor(0.0090, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 36 finished\n",
      "tensor(0.0090, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 37 finished\n",
      "tensor(0.0087, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 38 finished\n",
      "tensor(0.0087, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 39 finished\n",
      "tensor(0.0088, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 40 finished\n",
      "tensor(0.0087, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 41 finished\n",
      "tensor(0.0084, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 42 finished\n",
      "tensor(0.0083, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 43 finished\n",
      "tensor(0.0080, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 44 finished\n",
      "tensor(0.0080, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 45 finished\n",
      "tensor(0.0079, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 46 finished\n",
      "tensor(0.0077, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 47 finished\n",
      "tensor(0.0075, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 48 finished\n",
      "tensor(0.0073, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 49 finished\n",
      "tensor(0.0073, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 50 finished\n",
      "tensor(0.0073, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 51 finished\n",
      "tensor(0.0070, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 52 finished\n",
      "tensor(0.0067, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 53 finished\n",
      "tensor(0.0067, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 54 finished\n",
      "tensor(0.0068, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 55 finished\n",
      "tensor(0.0065, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 56 finished\n",
      "tensor(0.0064, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 57 finished\n",
      "tensor(0.0064, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 58 finished\n",
      "tensor(0.0062, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 59 finished\n",
      "tensor(0.0061, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 60 finished\n",
      "tensor(0.0062, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 61 finished\n",
      "tensor(0.0058, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 62 finished\n",
      "tensor(0.0058, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 63 finished\n",
      "tensor(0.0058, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 64 finished\n",
      "tensor(0.0057, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 65 finished\n",
      "tensor(0.0057, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 66 finished\n",
      "tensor(0.0056, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 67 finished\n",
      "tensor(0.0055, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 68 finished\n",
      "tensor(0.0053, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 69 finished\n",
      "tensor(0.0054, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 70 finished\n",
      "tensor(0.0052, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 71 finished\n",
      "tensor(0.0051, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 72 finished\n",
      "tensor(0.0050, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 73 finished\n",
      "tensor(0.0050, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 74 finished\n",
      "tensor(0.0050, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 75 finished\n",
      "tensor(0.0051, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 76 finished\n",
      "tensor(0.0050, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 77 finished\n",
      "tensor(0.0048, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 78 finished\n",
      "tensor(0.0049, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 79 finished\n",
      "tensor(0.0047, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 80 finished\n",
      "tensor(0.0047, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 81 finished\n",
      "tensor(0.0047, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 82 finished\n",
      "tensor(0.0048, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 83 finished\n",
      "tensor(0.0048, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 84 finished\n",
      "tensor(0.0046, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 85 finished\n",
      "tensor(0.0046, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 86 finished\n",
      "tensor(0.0044, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 87 finished\n",
      "tensor(0.0044, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 88 finished\n",
      "tensor(0.0043, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 89 finished\n",
      "tensor(0.0044, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 90 finished\n",
      "tensor(0.0044, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 91 finished\n",
      "tensor(0.0044, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 92 finished\n",
      "tensor(0.0044, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 93 finished\n",
      "tensor(0.0043, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 94 finished\n",
      "tensor(0.0043, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 95 finished\n",
      "tensor(0.0043, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 96 finished\n",
      "tensor(0.0042, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 97 finished\n",
      "tensor(0.0041, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 98 finished\n",
      "tensor(0.0040, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 99 finished\n",
      "tensor(0.0040, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 100 finished\n",
      "tensor(0.0041, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 101 finished\n",
      "tensor(0.0040, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 102 finished\n",
      "tensor(0.0042, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 103 finished\n",
      "tensor(0.0038, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 104 finished\n",
      "tensor(0.0039, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 105 finished\n",
      "tensor(0.0038, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 106 finished\n",
      "tensor(0.0039, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 107 finished\n",
      "tensor(0.0039, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 108 finished\n",
      "tensor(0.0039, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 109 finished\n",
      "tensor(0.0039, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 110 finished\n",
      "tensor(0.0040, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 111 finished\n",
      "tensor(0.0040, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 112 finished\n",
      "tensor(0.0039, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 113 finished\n",
      "tensor(0.0039, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 114 finished\n",
      "tensor(0.0038, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 115 finished\n",
      "tensor(0.0038, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 116 finished\n",
      "tensor(0.0039, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 117 finished\n",
      "tensor(0.0038, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 118 finished\n",
      "tensor(0.0038, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 119 finished\n",
      "tensor(0.0038, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 120 finished\n",
      "tensor(0.0038, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 121 finished\n",
      "tensor(0.0038, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 122 finished\n",
      "tensor(0.0037, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 123 finished\n",
      "tensor(0.0037, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 124 finished\n",
      "tensor(0.0038, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 125 finished\n",
      "tensor(0.0036, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 126 finished\n",
      "tensor(0.0034, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 127 finished\n",
      "tensor(0.0036, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 128 finished\n",
      "tensor(0.0036, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 129 finished\n",
      "tensor(0.0038, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 130 finished\n",
      "tensor(0.0036, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 131 finished\n",
      "tensor(0.0035, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 132 finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0035, grad_fn=<SmoothL1LossBackward>)\n",
      "Epoch 133 finished\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8d2afc84c446>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdisplacement\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperience_replay\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mMIN_REPLAY_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperience_replay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-a7f3d51ad5ba>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(replay_memory, main, target, batch_size)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprev_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mq_tminus1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqs_tminus1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mq_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqs_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mGAMMA\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mq_max\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "env.seed(5)  # comment out after testing\n",
    "\n",
    "max_step = 100\n",
    "displacement = 4\n",
    "epoch = 0\n",
    "step = 0\n",
    "\n",
    "main = Net(4,2)\n",
    "target = copy.deepcopy(main)\n",
    "\n",
    "\n",
    "experience_replay = deque(maxlen=SAMPLE_SIZE)\n",
    "\n",
    "epsilon = EPSILON_INITIAL\n",
    "while(epoch < MAX_EPOCHS):\n",
    "    if (epsilon < .01):\n",
    "        epsilon = .01\n",
    "    prev_obs = env.reset()\n",
    "    while True:\n",
    "        step += 1\n",
    "\n",
    "        # Epsilon Greedy\n",
    "        eps_sample = random.random()        \n",
    "        if eps_sample >= epsilon:\n",
    "            q = main.forward(torch.FloatTensor(prev_obs))\n",
    "            # exploitation\n",
    "            action = torch.argmax(q).item()\n",
    "        else:\n",
    "            # exploration\n",
    "            action = env.action_space.sample()\n",
    "        # decay epsilon after every random sample\n",
    "        # for more exploitation over time\n",
    "        epsilon = (1 - EPS_DECAY) * epsilon\n",
    "\n",
    "        obs, reward, done, info = env.step(env.action_space.sample())\n",
    "        experience_replay.append([prev_obs, reward, action, obs, done])\n",
    "\n",
    "\n",
    "        if (step % displacement == 0 and len(experience_replay) >= MIN_REPLAY_SIZE):\n",
    "            train(experience_replay, main, target, BATCH_SIZE)\n",
    "\n",
    "\n",
    "        prev_obs = obs\n",
    "        if (step >= max_step):\n",
    "            train(experience_replay, main, target, len(experience_replay))\n",
    "            \n",
    "            \n",
    "#             print(\"copying main to target\")\n",
    "            print(\"Epoch\", epoch, \"finished\")\n",
    "            target = copy.deepcopy(main)\n",
    "            step = 0\n",
    "            epoch += 1\n",
    "            if (epoch >= MAX_EPOCHS):\n",
    "                break\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "#     env.render()\n",
    "    step += 1\n",
    "print(\"Finished!\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.09813787  0.56478765 -0.21013758 -1.25954689]\n",
      "Model failed! on 20 Could not survive 1000 steps\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "obs = env.reset()\n",
    "N = 1000\n",
    "for t in range(N):\n",
    "    env.render()\n",
    "    time.sleep(.1)\n",
    "    x = torch.from_numpy(obs).float()\n",
    "    action_vect = main.forward(x)\n",
    "    action = torch.argmax(action_vect)\n",
    "    obs, reward, done, info = env.step(action.item())\n",
    "    if (done):\n",
    "        print(obs)\n",
    "        print(\"Model failed! on\", t, \"Could not survive\", N, \"steps\")\n",
    "        break;\n",
    "if t == N:\n",
    "    print(\"model success!\")\n",
    "time.sleep(1)\n",
    "env.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(2)\n",
      "Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (4,), float32)\n"
     ]
    }
   ],
   "source": [
    "print(env.action_space)\n",
    "print(env.observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
